{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Henter API\n",
    "\n",
    "I denne notebooken er den benyttet klasser fra filen \"Weather_analysis.py\" under mappen \"src\".\n",
    "\n",
    "Her henter vi inn API-et og lagrer det i en csv fil.\n",
    "Vi henter data for lufttemperatur, nedmørsmengde og vindhastighet over 45 år i Oslo på værstasjonen Oslo-Blindern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importerer biblioteker\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved from frost.met.no!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Skriver inn client Id\n",
    "client_id = '61f26ba4-3f68-4e56-a3b8-09733ceb82ed'\n",
    "\n",
    "# Definerer endpoint og parametere\n",
    "endpoint = 'https://frost.met.no/observations/v0.jsonld'\n",
    "parameters = {\n",
    "    'sources': 'SN18700',\n",
    "    'elements': 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)',\n",
    "    'referencetime': '1975-01-01/2020-12-31',\n",
    "}\n",
    "# Sender request\n",
    "r = requests.get(endpoint, parameters, auth=(client_id,''))\n",
    "# Får inn json data\n",
    "json = r.json()\n",
    "\n",
    "# Sjekker requesten, om den er 200 er det godkjent og dataen er mottatt. Sjekker errorene hvis status_code ikke er 200\n",
    "if r.status_code == 200:\n",
    "    data = json['data']\n",
    "    print('Data retrieved from frost.met.no!')\n",
    "else:\n",
    "    print('Error! Returned status code %s' % r.status_code)\n",
    "    print('Message: %s' % json['error']['message'])\n",
    "    print('Reason: %s' % json['error']['reason'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vis data\n",
    "\n",
    "Her benytter vi funksjonen \"extract_observations\" for å overføre dataen til en dataframe. Lagrer så dataen i et csv-format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           elementId  value  unit  \\\n",
      "0          mean(air_temperature P1D)   -2.3  degC   \n",
      "1          mean(air_temperature P1D)   -0.4  degC   \n",
      "2      sum(precipitation_amount P1D)    0.0    mm   \n",
      "3      sum(precipitation_amount P1D)    7.4    mm   \n",
      "4               mean(wind_speed P1D)    1.0   m/s   \n",
      "...                              ...    ...   ...   \n",
      "83989      mean(air_temperature P1D)    1.7  degC   \n",
      "83990      mean(air_temperature P1D)    2.3  degC   \n",
      "83991  sum(precipitation_amount P1D)    5.9    mm   \n",
      "83992  sum(precipitation_amount P1D)    5.6    mm   \n",
      "83993           mean(wind_speed P1D)    5.1   m/s   \n",
      "\n",
      "                                                   level timeOffset  \\\n",
      "0      {'levelType': 'height_above_ground', 'unit': '...       PT0H   \n",
      "1      {'levelType': 'height_above_ground', 'unit': '...       PT6H   \n",
      "2                                                    NaN      PT18H   \n",
      "3                                                    NaN       PT6H   \n",
      "4      {'levelType': 'height_above_ground', 'unit': '...       PT0H   \n",
      "...                                                  ...        ...   \n",
      "83989  {'levelType': 'height_above_ground', 'unit': '...       PT0H   \n",
      "83990  {'levelType': 'height_above_ground', 'unit': '...       PT6H   \n",
      "83991                                                NaN      PT18H   \n",
      "83992                                                NaN       PT6H   \n",
      "83993  {'levelType': 'height_above_ground', 'unit': '...       PT0H   \n",
      "\n",
      "      timeResolution  timeSeriesId performanceCategory exposureCategory  \\\n",
      "0                P1D             0                   C                2   \n",
      "1                P1D             0                   C                2   \n",
      "2                P1D             0                   C                2   \n",
      "3                P1D             0                   C                2   \n",
      "4                P1D             0                   C                2   \n",
      "...              ...           ...                 ...              ...   \n",
      "83989            P1D             0                   C                2   \n",
      "83990            P1D             0                   C                2   \n",
      "83991            P1D             0                   C                2   \n",
      "83992            P1D             0                   C                2   \n",
      "83993            P1D             0                   C                2   \n",
      "\n",
      "       qualityCode             referenceTime   sourceId  \n",
      "0              2.0  1975-01-01T00:00:00.000Z  SN18700:0  \n",
      "1              2.0  1975-01-01T00:00:00.000Z  SN18700:0  \n",
      "2              2.0  1975-01-01T00:00:00.000Z  SN18700:0  \n",
      "3              2.0  1975-01-01T00:00:00.000Z  SN18700:0  \n",
      "4              2.0  1975-01-01T00:00:00.000Z  SN18700:0  \n",
      "...            ...                       ...        ...  \n",
      "83989          0.0  2020-12-30T00:00:00.000Z  SN18700:0  \n",
      "83990          2.0  2020-12-30T00:00:00.000Z  SN18700:0  \n",
      "83991          2.0  2020-12-30T00:00:00.000Z  SN18700:0  \n",
      "83992          0.0  2020-12-30T00:00:00.000Z  SN18700:0  \n",
      "83993          2.0  2020-12-30T00:00:00.000Z  SN18700:0  \n",
      "\n",
      "[83994 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Benytter funskjon extract_observations fra Weather_analysis.py\n",
    "# Denne funskjonen skal hente ut og utvide hvert element av data. \n",
    "sys.path.append('../src')\n",
    "from Weather_analysis import ObservationProcessor\n",
    "processor = ObservationProcessor(data)\n",
    "rows = processor.extract_observations()\n",
    "\n",
    "# Oppretter en dataframe med de nye radene\n",
    "df = pd.DataFrame(rows)\n",
    "# Resetter indexen for et bedre format\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Lagrer den orginale dataen til en csv-fil\n",
    "df.to_csv('../data/weather_api_org.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyserer data\n",
    "\n",
    "Vi ser at vi har mange unødvendige kolonner, som gjør dataen uoversiktlig. Derfor fjerner vi kolonnene: \n",
    "\"level\", \"timeResolution\", \"timeSeriesId\", \"performanceCategory\", \"exposureCategory\", \"qualityCode\", \"sourceId\". Dette gjør vi med med å bruke funksjonen drop_columns. Denne funksjonen har vi lagt under klassen DataCleaner som vi benytter oss av her.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')  # Importer DataCleaner-klassen fra filen\n",
    "\n",
    "from Weather_analysis import DataCleaner\n",
    "\n",
    "\n",
    "# Opprett et objekt av DataCleaner og gi det DataFrame som input\n",
    "cleaner = DataCleaner(df)\n",
    "# Bruker funskjonen \"drop_columns\" fra DataCleaner for å fjerne kolonnene som er unødvendige. \n",
    "drop_columns=['level','timeResolution','timeSeriesId','performanceCategory','exposureCategory','qualityCode','sourceId']\n",
    "df = cleaner.drop_columns(drop_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legger til en kolonne 'dato'\n",
    "\n",
    "Vi legger til en kolonne som viser dato, uten klokkeslett\n",
    "\n",
    "Dette gjør vi ved å legge til kolonnen vi kaller \"date\" og gjør om teksten i kolonnen \"referenceTime\" til datetime-format, slik at vi kan hente ut datoen uten tiden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gjør om refrenceTime til datetime_format og henter ut datoen, og kaller denne kolonnen for \"date\"\n",
    "df['date'] = pd.to_datetime(df['referenceTime']).dt.date\n",
    "\n",
    "# Legger den nye kolonnen \"date\" først, og de gamle kolonnene etter den, også oppdaterer dataframen med nye kolonner\n",
    "cols = ['date'] + [col for col in df.columns if col != 'date']\n",
    "df = df[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fjerner verdier som ikke gir mening\n",
    "Vi velger å fjerne rader for temperatur der verdiene enten er under -50 eller over 60, fordi dette gir ikke mening og er sannsynligvis feil måling. Til slutt sjekker vi antall rader som er fjernet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rader fjernet er: 0\n"
     ]
    }
   ],
   "source": [
    "# Sjekker antall rader før filtrering\n",
    "rows_before = len(df)\n",
    "\n",
    "# Bruk df.loc for å kun beholde verdier på målinger som ikke gir mening, basert på historisk data for våre elementer i Norge\n",
    "df_filtered = df.loc[((df['elementId'] == 'mean(air_temperature P1D)') & \n",
    "                     (df['value'] >= -50) & \n",
    "                     (df['value'] <= 45)) |\n",
    "\n",
    "                     ((df['elementId'] == 'sum(precipitation_amount P1D)') & \n",
    "                     (df['value'] >= 0) & \n",
    "                     (df['value'] <= 230)) |\n",
    "\n",
    "                     ((df['elementId'] == 'mean(wind_speed P1D)') & \n",
    "                     (df['value'] >= 0) & \n",
    "                     (df['value'] <= 82)) ]\n",
    "\n",
    "# Sjekker antall rader etter filtrering\n",
    "rows_after = len(df_filtered)\n",
    "\n",
    "# Sjekker antall rader fjernet\n",
    "rows_removed = rows_before - rows_after\n",
    "\n",
    "print(f'Antall rader fjernet er: {rows_removed}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sletter manglende verdier\n",
    "Her brukes funksjonen dropna() som fjerner rader der det mangler verdier. I dette tilfellet sjekker vi kolonnen \"value\". Deretter sjekker vi antall rader som er fjernet med funksjonen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rader fjernet er: 0\n"
     ]
    }
   ],
   "source": [
    "# Sjekker om det er noen manglende data\n",
    "\n",
    "rows_before = len(df)\n",
    "\n",
    "missing_value = df.dropna(subset=['value'])\n",
    "\n",
    "rows_after = len(missing_value)\n",
    "\n",
    "rows_removed = rows_before - rows_after\n",
    "\n",
    "print(f'Antall rader fjernet er: {rows_removed}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finner gjennomsnittsverdier per dag\n",
    "Vi ser at alle målinger er innefor vårt gyldighetsområde og det er verdier for hver dag, og jobber derfor videre med alle rader. I csv-filen er det to målinger per dag for air_temperature og presipitation_amount. Disse vil vi finne gjennomsnittet av, slik at vi kun har en måling per element per dag. Med pandas funksjonen groupby fjernes også automatisk kolonnene timeOffset og referenceTime, slik vi ønsker.\n",
    "\n",
    "Framgangsmåten er å bruke groupby for å gruppere etter dato og elementId. Under kolonnen \"value\" finner vi gjennomsnittet over gruppen, og for kolonnen \"unit\" brukes første enhet. Verdiene rundes av til 3 desimaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date                      elementId  value  unit\n",
      "0  1975-01-01      mean(air_temperature P1D)  -1.35  degC\n",
      "1  1975-01-01           mean(wind_speed P1D)   1.00   m/s\n",
      "2  1975-01-01  sum(precipitation_amount P1D)   3.70    mm\n",
      "3  1975-01-02      mean(air_temperature P1D)  -0.75  degC\n",
      "4  1975-01-02           mean(wind_speed P1D)   1.00   m/s\n"
     ]
    }
   ],
   "source": [
    "# Gruppér og ta gjennomsnitt per dag og elementId\n",
    "aggregert = df.groupby(['date', 'elementId']).agg({\n",
    "    'value': 'mean',\n",
    "    'unit': 'first',  # beholder enheten\n",
    "}).round(3).reset_index()\n",
    "\n",
    "aggregert.to_csv('../data/gjsnitt_data.csv')\n",
    "\n",
    "print(aggregert.head())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
